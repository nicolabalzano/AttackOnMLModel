{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nikba\\AppData\\Local\\Temp\\ipykernel_5016\\853796466.py:21: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Trains a convolutional neural network on the MNIST dataset, then attacks one of the hidden layers with the FGSM\n",
    "attack.\"\"\"\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "from os.path import abspath\n",
    "\n",
    "sys.path.append(abspath(\".\"))\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.utils import load_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.backend' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mKerasClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmin_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, nb_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Attack one of the inner layers, instead of the input one. In this example\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# we are going to attack the second convolutional layer. To this aim, we need to\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# split the network in 2 sub-nets, in order to have has input layer of the\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# second network, the layer we want to attack\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\art\\estimators\\classification\\keras.py:129\u001b[0m, in \u001b[0;36mKerasClassifier.__init__\u001b[1;34m(self, model, use_logits, channels_first, clip_values, preprocessing_defences, postprocessing_defences, preprocessing, input_layer, output_layer)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of model not recognized:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)))\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\art\\estimators\\classification\\keras.py:260\u001b[0m, in \u001b[0;36mKerasClassifier._initialize_params\u001b[1;34m(self, model, use_logits, input_layer, output_layer)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(loss_function)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m loss_function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     ]\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m flag_is_instance:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m     label_ph \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(loss_function) \u001b[38;5;129;01mand\u001b[39;00m loss_function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    263\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_function, keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy):\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.backend' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Read MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"mnist\"))\n",
    "\n",
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Attack one of the inner layers, instead of the input one. In this example\n",
    "# we are going to attack the second convolutional layer. To this aim, we need to\n",
    "# split the network in 2 sub-nets, in order to have has input layer of the\n",
    "# second network, the layer we want to attack\n",
    "\n",
    "HL_model = Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "\n",
    "DL_input = Input(model.layers[3].input_shape[1:])\n",
    "DL_model = DL_input\n",
    "for layer in model.layers[3:]:\n",
    "    DL_model = layer(DL_model)\n",
    "DL_model = Model(inputs=DL_input, outputs=DL_model)\n",
    "\n",
    "classifier = KerasClassifier(model=DL_model)\n",
    "\n",
    "# Now we need to create the dataset for the DL_model, since the original one is\n",
    "# suited only for the \"model\" network (and thus for the HL_model). Note that it\n",
    "# is not needed to change the labels\n",
    "x_test_inner = HL_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier on the test set\n",
    "preds = np.argmax(classifier.predict(x_test_inner), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc * 100))\n",
    "\n",
    "# Craft adversarial samples with FGSM\n",
    "epsilon = 0.1  # Maximum perturbation\n",
    "adv_crafter = FastGradientMethod(classifier, eps=epsilon)\n",
    "x_test_adv = adv_crafter.generate(x=x_test_inner)\n",
    "\n",
    "# Evaluate the classifier on the adversarial examples\n",
    "preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy on adversarial sample: %.2f%%\" % (acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
